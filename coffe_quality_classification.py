# -*- coding: utf-8 -*-
"""coffe_roasted_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MRxvSTeEYku3vI6OkHuege_bkEgDWdtL

# **Analisis Perbandingan CNN dan Transfer Learning dalam Klasifikasi Citra Tingkat Kematangan Sangrai Biji Kopi**

---



Notebook ini dibuat untuk memenuhi tugas UAS Mata Kuliah Deep Learning.

Penelitian ini bertujuan untuk melakukan klasifikasi tingkat kematangan (roasting level) biji kopi
menggunakan citra digital dan metode Deep Learning berbasis Convolutional Neural Network (CNN)
serta Transfer Learning.

Dataset yang digunakan adalah **Coffee Roasted Image Dataset** yang terdiri dari **4 kelas**
tingkat roasting biji kopi, yaitu:
- Light Roast
- Medium Roast
- Dark Roast
- Green Bean

Dataset telah disimpan dan diakses melalui Google Drive.

# **Step 1 | Configurasi dan Import Library**
"""

import os
import collections
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
import matplotlib.pyplot as plt

import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
from plotly.subplots import make_subplots
from google.colab import drive

sns.set_style("white")
pio.renderers.default = "colab"

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

"""# **Step 2 | Load Dataset**"""

from google.colab import drive
drive.mount('/content/drive')

DATASET_PATH = "/content/drive/MyDrive/coffe-roasted/train"

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE
SEED = 42

dataset = tf.keras.utils.image_dataset_from_directory(
    DATASET_PATH,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=42
)

CLASS_NAMES = dataset.class_names

print(f"Found {len(CLASS_NAMES)} classes.")
print("\nCoffe classes:")
print("\n".join(CLASS_NAMES))

import os

print("\nCoffe classes and number of files:")
total = 0
for cls in CLASS_NAMES:
    count = len([
        f for f in os.listdir(os.path.join(DATASET_PATH, cls))
        if f.lower().endswith(('.png', '.jpg', '.jpeg'))
    ])
    total += count
    print(f"- {cls:<7} : {count}")

print(f"\nTotal files: {total}")

"""# **Step 3 | Eksplorasi Dataset**

### *3.1 Distribusi Jumlah data per kelas*
"""

# @title
import os
from collections import OrderedDict
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.express as px

class_counts = OrderedDict()

for cls in CLASS_NAMES:
    class_dir = os.path.join(DATASET_PATH, cls)
    class_counts[cls] = len([
        f for f in os.listdir(class_dir)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ])

classes = list(class_counts.keys())
counts  = list(class_counts.values())

fig = make_subplots(
    rows=1, cols=2,
    specs=[[{'type': 'xy'}, {'type': 'domain'}]],
    subplot_titles=("Number of Images per Class", "Coffee Classes Distribution")
)

fig.add_trace(
    go.Bar(
        y=classes,
        x=counts,
        orientation='h',
        text=counts,
        textposition='outside',
        marker_color='#1A3636',
        cliponaxis=False,
        hovertemplate="Class: %{y}<br>Samples: %{x}<extra></extra>"
    ),
    row=1, col=1
)

fig.add_trace(
    go.Pie(
        labels=classes,
        values=counts,
        hole=0.35,
        textinfo='label+percent',
        marker_colors=px.colors.sequential.Greens,
        hoverinfo='label+value+percent'
    ),
    row=1, col=2
)

fig.update_layout(
    title=dict(
        text="Coffee Dataset Distribution: Bar Chart and Pie Chart",
        x=0.5,
        font=dict(size=22)
    ),
    autosize=True,
    height=550,
    margin=dict(l=160, r=160, t=80, b=50),
    plot_bgcolor='white',
    paper_bgcolor='white'
)

fig.update_xaxes(title_text="Number of Samples", row=1, col=1)
fig.update_yaxes(title_text="Classes", row=1, col=1)

fig.show()

"""### *3.2 Visualisasi contoh citra*"""

plt.figure(figsize=(15, 6))

for i, cls in enumerate(CLASS_NAMES):
    class_dir = os.path.join(DATASET_PATH, cls)

    img_name = sorted([
        f for f in os.listdir(class_dir)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ])[0]

    img_path = os.path.join(class_dir, img_name)
    img = plt.imread(img_path)

    plt.subplot(1, len(CLASS_NAMES), i + 1)
    plt.imshow(img)
    plt.title(cls, fontsize=14, fontweight='bold')
    plt.axis('off')

plt.show()

"""# **Step 4 | Split Dataset (70/15/15)**

### *4.1 Integrasi Data*
"""

coffee_classes = sorted([
    d for d in os.listdir(DATASET_PATH)
    if os.path.isdir(os.path.join(DATASET_PATH, d))
])

print("Coffee classes:")
for cls in coffee_classes:
    print("-", cls)

print("\nTotal classes:", len(coffee_classes))

image_paths = []
image_labels = []

for coffee_class in coffee_classes:
    class_dir = os.path.join(DATASET_PATH, coffee_class)

    for img_name in os.listdir(class_dir):
        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
            full_path = os.path.join(class_dir, img_name)
            image_paths.append(full_path)
            image_labels.append(coffee_class)

df = pd.DataFrame({
    "File_Path": image_paths,
    "Label": image_labels
})

df.head(10)

print("Distribusi label:")
print(df["Label"].value_counts())

print("\nTotal images:", len(df))

for i in range(5):
    path = df.loc[i, "File_Path"]
    label = df.loc[i, "Label"]
    folder = path.split("/")[-2]
    print(f"{folder:<10} | Label: {label:<10} | Match: {folder == label}")

"""### *4.2 Data Training*"""

train_df, temp_df = train_test_split(
    df,
    test_size=0.30,
    stratify=df['Label'],
    random_state=42
)

"""### *4.3 Data Testing dan Testing*"""

val_df, test_df = train_test_split(
    temp_df,
    test_size=0.50,
    stratify=temp_df['Label'],
    random_state=42
)

"""### *4.4 Visualisasi Split Data*"""

# @title
import matplotlib.pyplot as plt

def visualize_split_distribution(train_df, val_df, test_df):
    colors = ['#4CAF50', '#7CB342', '#CDDC39', '#FFEB3B',
              '#FFC107', '#FF9800', '#FF5722', '#F44336',
              '#E91E63', '#9C27B0']

    fig, axs = plt.subplots(1, 3, figsize=(18, 6))

    datasets = [
        (train_df, "Training Set"),
        (val_df, "Validation Set"),
        (test_df, "Test Set")
    ]

    for i, (subset, title) in enumerate(datasets):
        counts = subset['Label'].value_counts().sort_index()
        total = len(subset)

        wedges, texts, autotexts = axs[i].pie(
            counts.values,
            labels=counts.index,
            autopct=lambda p: f"{p:.1f}%\n({int(p*total/100)})",
            startangle=90,
            colors=colors[:len(counts)],
            textprops={'fontsize': 10}
        )

        axs[i].set_title(f"{title}\nTotal: {total}", fontsize=13)
        axs[i].axis('equal')

    plt.suptitle("Dataset Split Distribution per Class", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

visualize_split_distribution(train_df, val_df, test_df)

"""# **Step 5 | Preprocessing**

### *5.1 Label Encoding*
"""

# Ambil kelas dari TRAIN (aman, no leakage)
class_names = sorted(train_df['Label'].unique())

label_to_index = {label: idx for idx, label in enumerate(class_names)}
index_to_label = {idx: label for label, idx in label_to_index.items()}

# Tambahkan kolom label numerik
train_df['Label_ID'] = train_df['Label'].map(label_to_index)
val_df['Label_ID']   = val_df['Label'].map(label_to_index)
test_df['Label_ID']  = test_df['Label'].map(label_to_index)

"""### *5.2 Fungsi Load, JPG to RGB, Resize, Normalisasi*"""

def load_and_preprocess_image(path, label):
    image = tf.io.read_file(path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, IMG_SIZE)
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

"""### *5.3 Build Dataset*"""

def build_dataset_basic(df):
    paths  = df["File_Path"].values
    labels = df["Label_ID"].values

    ds = tf.data.Dataset.from_tensor_slices((paths, labels))
    ds = ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)
    ds = ds.batch(BATCH_SIZE)
    ds = ds.prefetch(AUTOTUNE)
    return ds

train_ds = build_dataset_basic(train_df)
val_ds   = build_dataset_basic(val_df)
test_ds  = build_dataset_basic(test_df)

for images, labels in train_ds.take(1):
    print("Images shape:", images.shape)
    print("Labels shape:", labels.shape)

"""# Step **6 | Data Augmentation**"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomTranslation(0.05, 0.05),
], name="data_augmentation")

def augment_dataset(ds):
    return ds.map(
        lambda x, y: (data_augmentation(x, training=True), y),
        num_parallel_calls=tf.data.AUTOTUNE
    )

train_ds_aug = augment_dataset(train_ds)

val_ds = val_ds.prefetch(tf.data.AUTOTUNE)
test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

# @title
import matplotlib.pyplot as plt

# Ambil 1 batch asli
orig_images, orig_labels = next(iter(train_ds))

# Ambil 1 batch yang sudah diaugmentasi
aug_images, aug_labels = next(iter(train_ds_aug))

plt.figure(figsize=(12, 6))

for i in range(5):
    # Original
    plt.subplot(2, 5, i + 1)
    plt.imshow(orig_images[i].numpy())
    plt.title("Original")
    plt.axis("off")

    # Augmented
    plt.subplot(2, 5, i + 6)
    plt.imshow(aug_images[i].numpy())
    plt.title("Augmented")
    plt.axis("off")

plt.tight_layout()
plt.show()

"""# **Step 7 | Build Model**

### *7.1 CNN Custom*
"""

NUM_CLASSES = len(class_names)

cnn_model = tf.keras.Sequential([
    layers.Input(shape=(224, 224, 3)),

    layers.Conv2D(32, 3, activation='relu', padding='same'),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, activation='relu', padding='same'),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation='relu', padding='same'),
    layers.MaxPooling2D(),

    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(NUM_CLASSES, activation='softmax')
])

cnn_model.summary()

"""### *7.2 Transfer Learning (MobileNetV2)*"""

base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet"
)

base_model.trainable = False  # FREEZE


mobilenet_model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(224, 224, 3)),
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(256, activation="relu"),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(class_names), activation="softmax")
])


mobilenet_model.summary()

"""# **Step 8 | Compile & Train Model**

### *8.1 Konfigurasi Training Global*
"""

EPOCHS = 25
LEARNING_RATE = 1e-4

"""### *8.2 Callback*"""

callbacks = [
    tf.keras.callbacks.EarlyStopping(
        monitor="val_loss",
        patience=5,
        restore_best_weights=True
    ),
    tf.keras.callbacks.ModelCheckpoint(
        filepath="best_model.h5",
        monitor="val_accuracy",
        save_best_only=True
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss",
        factor=0.3,
        patience=3,
        min_lr=1e-6
    )
]

"""### *8.3 Compile Training CNN vs Transfer Learning (MobileNetv2)*

- CNN
"""

cnn_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=["accuracy"]
)

"""- Transfer Learning (MobileNetv2)"""

mobilenet_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=["accuracy"]
)

"""### *8.4 Training CNN vs Transfer Learning (MobileNetv2)*

- CNN
"""

# CNN
history_cnn = cnn_model.fit(
    train_ds_aug,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks
)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history_cnn.history["accuracy"], label="Train Accuracy")
plt.plot(history_cnn.history["val_accuracy"], label="Val Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("CNN Accuracy")
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history_cnn.history["loss"], label="Train Loss")
plt.plot(history_cnn.history["val_loss"], label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("CNN Loss")
plt.legend()

plt.tight_layout()
plt.show()

"""- Transfer Learning (MobileNetv2)"""

# MobileNetV2
history_mobilenet = mobilenet_model.fit(
    train_ds_aug,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks
)

plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history_mobilenet.history["accuracy"], label="Train Accuracy")
plt.plot(history_mobilenet.history["val_accuracy"], label="Val Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("MobileNetV2 Accuracy")
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history_mobilenet.history["loss"], label="Train Loss")
plt.plot(history_mobilenet.history["val_loss"], label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("MobileNetV2 Loss")
plt.legend()

plt.tight_layout()
plt.show()

final_results = {
    "CNN_Train_Acc": history_cnn.history["accuracy"][-1],
    "CNN_Val_Acc": history_cnn.history["val_accuracy"][-1],
    "MobileNet_Train_Acc": history_mobilenet.history["accuracy"][-1],
    "MobileNet_Val_Acc": history_mobilenet.history["val_accuracy"][-1],
}

for k, v in final_results.items():
    print(f"{k:<25}: {v:.4f}")

import matplotlib.pyplot as plt

def compare_history(h1, h2, name1="CNN", name2="MobileNetV2"):
    fig, axs = plt.subplots(2, 2, figsize=(18, 10))

    # Train Accuracy
    axs[0,0].plot(h1.history["accuracy"], label=name1)
    axs[0,0].plot(h2.history["accuracy"], "--", label=name2)
    axs[0,0].set_title("Train Accuracy")
    axs[0,0].legend()

    # Val Accuracy
    axs[0,1].plot(h1.history["val_accuracy"], label=name1)
    axs[0,1].plot(h2.history["val_accuracy"], "--", label=name2)
    axs[0,1].set_title("Validation Accuracy")
    axs[0,1].legend()

    # Train Loss
    axs[1,0].plot(h1.history["loss"], label=name1)
    axs[1,0].plot(h2.history["loss"], "--", label=name2)
    axs[1,0].set_title("Train Loss")
    axs[1,0].legend()

    # Val Loss
    axs[1,1].plot(h1.history["val_loss"], label=name1)
    axs[1,1].plot(h2.history["val_loss"], "--", label=name2)
    axs[1,1].set_title("Validation Loss")
    axs[1,1].legend()

    plt.tight_layout()
    plt.show()

compare_history(history_cnn, history_mobilenet)

"""# **Step 9 | Evaluasi Model**

### *9.1 CNN*

- Test Acuraccy dan Loss
"""

test_loss_cnn, test_acc_cnn = cnn_model.evaluate(test_ds, verbose=1)
print(f"CNN Test Accuracy: {test_acc_cnn:.4f}")

"""- Ambil Label Asli & Prediksi"""

import numpy as np

y_true = []
y_pred_cnn = []

for images, labels in test_ds:
    preds = cnn_model.predict(images, verbose=0)
    y_true.extend(labels.numpy())
    y_pred_cnn.extend(np.argmax(preds, axis=1))

"""- Confusion Matrix"""

cm_cnn = confusion_matrix(y_true, y_pred_cnn)

disp_cnn = ConfusionMatrixDisplay(
    confusion_matrix=cm_cnn,
    display_labels=class_names
)

disp_cnn.plot(cmap="Blues", xticks_rotation=45)
plt.title("Confusion Matrix – CNN")
plt.show()

"""- Classification Report"""

from sklearn.metrics import classification_report

print("Classification Report – CNN")
print(classification_report(
    y_true,
    y_pred_cnn,
    target_names=class_names
))

"""### *9.2 MobileNetV2*

- Test Acuraccy dan Loss
"""

test_loss_tl, test_acc_tl = mobilenet_model.evaluate(test_ds, verbose=1)
print(f"MobileNetV2 Test Accuracy: {test_acc_tl:.4f}")

"""- Ambil Label Asli & Prediksi"""

y_pred_tl = []

for images, labels in test_ds:
    preds = mobilenet_model.predict(images, verbose=0)
    y_pred_tl.extend(np.argmax(preds, axis=1))

"""- Confusion Matrix"""

cm_tl = confusion_matrix(y_true, y_pred_tl)

disp_tl = ConfusionMatrixDisplay(
    confusion_matrix=cm_tl,
    display_labels=class_names
)

disp_tl.plot(cmap="Greens", xticks_rotation=45)
plt.title("Confusion Matrix – MobileNetV2")
plt.show()

"""- Classification Report"""

print("Classification Report – MobileNetV2")
print(classification_report(
    y_true,
    y_pred_tl,
    target_names=class_names
))

"""### *9.3 Perbandingan CNN vs MobileNet*"""

import seaborn as sns

fig, axs = plt.subplots(1, 2, figsize=(18, 6))

sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names, ax=axs[0])
axs[0].set_title("CNN Confusion Matrix")
axs[0].set_xlabel("Predicted")
axs[0].set_ylabel("True")

sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Greens',
            xticklabels=class_names, yticklabels=class_names, ax=axs[1])
axs[1].set_title("MobileNetV2 Confusion Matrix")
axs[1].set_xlabel("Predicted")
axs[1].set_ylabel("True")

plt.tight_layout()
plt.show()

import pandas as pd

results_df = pd.DataFrame({
    "Model": ["CNN Custom", "MobileNetV2"],
    "Test Accuracy": [test_acc_cnn, test_acc_tl]
})

results_df

"""# **Step 10 | Prediksi dan Analisis Hasil**

### *10.1 Ambil Label Asli & Prediksi (CNN & MobileNetV2)*
"""

import numpy as np

# Ground truth
y_true = []

# Prediksi
y_pred_cnn = []
y_pred_tl  = []

for images, labels in test_ds:
    # simpan label asli
    y_true.extend(labels.numpy())

    # CNN
    preds_cnn = cnn_model.predict(images, verbose=0)
    y_pred_cnn.extend(np.argmax(preds_cnn, axis=1))

    # MobileNetV2
    preds_tl = mobilenet_model.predict(images, verbose=0)
    y_pred_tl.extend(np.argmax(preds_tl, axis=1))

y_true = np.array(y_true)
y_pred_cnn = np.array(y_pred_cnn)
y_pred_tl  = np.array(y_pred_tl)

"""### 10.2 Fungsi Visualisasi Prediksi (BENAR / SALAH)*teks yang dimiringkan*"""

import matplotlib.pyplot as plt

def visualize_predictions(
    dataset,
    y_true,
    y_pred,
    class_names,
    title,
    correct=True,
    max_images=5
):
    images_shown = 0
    plt.figure(figsize=(15, 5))

    idx = 0
    for images, labels in dataset:
        for i in range(len(images)):
            if images_shown >= max_images:
                break

            true_label = y_true[idx]
            pred_label = y_pred[idx]

            if (pred_label == true_label) == correct:
                plt.subplot(1, max_images, images_shown + 1)
                plt.imshow(images[i].numpy())
                plt.title(
                    f"True: {class_names[true_label]}\n"
                    f"Pred: {class_names[pred_label]}",
                    color="green" if correct else "red",
                    fontsize=11
                )
                plt.axis("off")
                images_shown += 1

            idx += 1

        if images_shown >= max_images:
            break

    plt.suptitle(title, fontsize=14, fontweight="bold")
    plt.show()

"""- **CNN**"""

visualize_predictions(
    test_ds,
    y_true,
    y_pred_cnn,
    class_names,
    title="Correct Predictions - CNN",
    correct=True
)

visualize_predictions(
    test_ds,
    y_true,
    y_pred_cnn,
    class_names,
    title="Wrong Predictions - CNN",
    correct=False
)

"""- **MobileNetV2**"""

visualize_predictions(
    test_ds,
    y_true,
    y_pred_tl,
    class_names,
    title="Correct Predictions - MobileNetV2",
    correct=True
)

visualize_predictions(
    test_ds,
    y_true,
    y_pred_tl,
    class_names,
    title="Wrong Predictions - MobileNetV2",
    correct=False
)

"""# **Step 11 | Perbandingan Hasil Model**"""

print("Final Test Accuracy")
print()
print(f"CNN           : {test_acc_cnn:.4f}")
print(f"MobileNetV2   : {test_acc_tl:.4f}")

import pandas as pd

comparison_df = pd.DataFrame({
    "Model": ["CNN Custom", "MobileNetV2 (Transfer Learning)"],
    "Test Accuracy": [test_acc_cnn, test_acc_tl]
})

comparison_df

import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4))
plt.bar(
    comparison_df["Model"],
    comparison_df["Test Accuracy"],
    color=["#1A3636", "#4CAF50"]
)
plt.ylim(0, 1)
plt.ylabel("Test Accuracy")
plt.title("Comparison of Model Performance")
plt.grid(axis="y", linestyle="--", alpha=0.6)
plt.show()

"""# **Step 12 | Ringkasan Kesimpulan dan Simpan Model**

Berdasarkan hasil pengujian pada data uji, model MobileNetV2 dengan pendekatan transfer learning memberikan performa terbaik dibandingkan CNN custom dalam klasifikasi tingkat roasted kopi. MobileNetV2 mampu mencapai akurasi yang lebih tinggi karena memanfaatkan fitur visual hasil pelatihan pada dataset berskala besar (ImageNet).

Sementara itu, CNN custom tetap menunjukkan performa yang cukup baik, namun membutuhkan data dan pelatihan yang lebih banyak untuk menandingi transfer learning. Oleh karena itu, transfer learning lebih direkomendasikan untuk kasus klasifikasi citra dengan dataset terbatas.
"""

if test_acc_tl > test_acc_cnn:
    best_model_name = "MobileNetV2"
else:
    best_model_name = "CNN Custom"

print(f"Best Model Based on Test Accuracy: {best_model_name}")

cnn_model.save("cnn_custom_model.h5")
mobilenet_model.save("mobilenetv2_model.h5")

print("Models saved successfully:")
print("- cnn_custom_model.h5")
print("- mobilenetv2_model.h5")

#from tensorflow.keras.models import load_model

#cnn_loaded = load_model("cnn_custom_model.h5")
#mobilenet_loaded = load_model("mobilenetv2_model.h5")

#print("Models loaded successfully")